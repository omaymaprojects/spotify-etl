{
	"jobConfig": {
		"name": "spotify job",
		"description": "",
		"role": "arn:aws:iam::624513649339:role/AWSGlueServiceRole-spotify",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 12,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "spotify job.py",
		"scriptLocation": "s3://aws-glue-assets-624513649339-us-west-2/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-08-28T10:42:37.353Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-624513649339-us-west-2/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": false,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-624513649339-us-west-2/sparkHistoryLogs/",
		"flexExecution": true,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "from awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nimport sys  # Ensure the sys module is imported\r\n\r\n## @params: [JOB_NAME]\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\n\r\n# Initialize Spark and Glue Contexts\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# Load data from the Glue Data Catalog for each table\r\nalbums = glueContext.create_dynamic_frame.from_catalog(database=\"spotify_database\", table_name=\"albums\")\r\nartists = glueContext.create_dynamic_frame.from_catalog(database=\"spotify_database\", table_name=\"artists\")\r\ntracks = glueContext.create_dynamic_frame.from_catalog(database=\"spotify_database\", table_name=\"tracks\")\r\n\r\n# Example transformations: Select specific fields\r\nalbums_transformed = albums.select_fields(['album_id', 'album_name', 'release_date', 'artist_id'])\r\nartists_transformed = artists.select_fields(['artist_id', 'artist_name', 'genre'])\r\ntracks_transformed = tracks.select_fields(['track_id', 'album_id', 'track_name', 'popularity'])\r\n\r\n# Join albums and artists on artist_id\r\nalbums_artists_joined = Join.apply(albums_transformed, artists_transformed, 'artist_id', 'artist_id')\r\n\r\n# Join the result with tracks on album_id\r\nfinal_transformed = Join.apply(albums_artists_joined, tracks_transformed, 'album_id', 'album_id')\r\n\r\n# Write the final transformed data to S3 in Parquet format\r\nglueContext.write_dynamic_frame.from_options(\r\n    frame=final_transformed,\r\n    connection_type=\"s3\",\r\n    connection_options={\"path\": \"s3://spotify-data-engineering/data-warehouse/final_data/\"},\r\n    format=\"parquet\"\r\n)\r\n\r\n# Commit the job\r\njob.commit()\r\n"
}